{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "spam.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Zl8lD4jfC4dr",
        "outputId": "6c82285b-fcfd-42f1-9fc6-17938d1ce67f"
      },
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk import tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Алексей\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Алексей\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5FpFjL-3C4dz"
      },
      "source": [
        "data = pd.read_csv('sms_spam.csv', usecols=[0, 1])\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.text, data.type , train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1zRxe0nGC4d1"
      },
      "source": [
        "class spamClassifier:\n",
        "  def __init__(self,\n",
        "               lower_case = True,\n",
        "               stop_words = {},\n",
        "               ngram_range = (1,5),\n",
        "               analyzer = 'char',\n",
        "               max_df = 1,\n",
        "               min_df = 1,\n",
        "               max_features = 1000,\n",
        "               Vectorizer = TfidfVectorizer):\n",
        "\n",
        "     self.Vectorizer = Vectorizer(lowercase=lower_case,\n",
        "                                       stop_words=stop_words,\n",
        "                                       ngram_range=ngram_range,\n",
        "                                       analyzer=analyzer,\n",
        "                                       tokenizer=self.tokenize,\n",
        "                                       max_df=max_df,\n",
        "                                       min_df=min_df,\n",
        "                                       max_features=max_features)\n",
        "  def tokenize(self, text):\n",
        "    text = ''.join([ch for ch in text if ch not in string.punctuation])\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "  def fit(self, x_train, y_train):\n",
        "    vect_x_train = self.Vectorizer.fit_transform(raw_documents = x_train)\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(vect_x_train, y_train)\n",
        "    self.classifier = clf\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    vect_x_test = self.Vectorizer.transform(x_test)\n",
        "    return self.classifier.predict(vect_x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hq7HueSsC4d4"
      },
      "source": [
        "class spamClassifierGrid:\n",
        "  def __init__(self,\n",
        "               low_case_set = [True],\n",
        "               stop_words_set = [ stopwords.words('english')],\n",
        "               analyzer_set = ['word', 'char' ],\n",
        "               ngram_range_set = [[1, 5], [3, 10]],\n",
        "               vectorizer_set = [TfidfVectorizer],\n",
        "               min_df_set = np.linspace(0, 1, 5),\n",
        "               max_df_set = np.linspace(0, 1, 5),\n",
        "               max_features_set = np.linspace(1000, 20000, 5)\n",
        "               ):\n",
        "    self.classifier_set = []\n",
        "    for case in low_case_set:\n",
        "        for stWord in stop_words_set:\n",
        "          for analyzer in analyzer_set:\n",
        "            for n1 in ngram_range_set[0]:\n",
        "              for n2 in ngram_range_set[1]:\n",
        "                if (n1 < n2):\n",
        "                  for vectorizer in vectorizer_set:\n",
        "                    for minDf in min_df_set:\n",
        "                      for maxDf in max_df_set:\n",
        "                        if (minDf <= maxDf):\n",
        "                          for max_feature in max_features_set:\n",
        "                            self.classifier_set.append(spamClassifier(\n",
        "                                  lower_case=case,\n",
        "                                  stop_words=stWord,\n",
        "                                  ngram_range=(n1, n2),\n",
        "                                  analyzer=analyzer,\n",
        "                                  max_df=maxDf,\n",
        "                                  min_df=minDf,\n",
        "                                  max_features=int(max_feature),\n",
        "                                  Vectorizer=vectorizer))\n",
        "\n",
        "\n",
        "  def fit(self, x_train, y_train):\n",
        "    fitted_list = []\n",
        "    for classifier in self.classifier_set:\n",
        "      try:\n",
        "        classifier.fit(x_train, y_train)\n",
        "        fitted_list.append(classifier)\n",
        "      except:\n",
        "        pass\n",
        "    self.classifier_set = fitted_list\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    self.predicted = []\n",
        "    for classifier in  self.classifier_set:\n",
        "      self.predicted.append(classifier.predict(x_test))\n",
        "    return self.predicted\n",
        "\n",
        "  def getReport(self, x_test, y_test):\n",
        "    report = pd.DataFrame(columns = ['Low word case',\n",
        "                                     'Stop words',\n",
        "                                     'n-gramm type',\n",
        "                                     'n-gramm range',\n",
        "                                     'max_df',\n",
        "                                     'min_df',\n",
        "                                     'max features',\n",
        "                                     'Vectorizer',\n",
        "                                     'precision',\n",
        "                                     'recall',\n",
        "                                     'f1-score',\n",
        "                                     'accuracy'])\n",
        "    for i in range(len(self.classifier_set)):\n",
        "      params = self.classifier_set[i].Vectorizer.get_params()\n",
        "      pred = self.classifier_set[i].predict(x_test)\n",
        "      report.loc[i] = {'Low word case' : params.get('lowercase'),\n",
        "                       'Stop words': (params.get('stop_words') != {}),\n",
        "                       'n-gramm type' : params.get('analyzer'),\n",
        "                       'n-gramm range' : params.get('ngram_range'),\n",
        "                       'max_df' : params.get('max_df'),\n",
        "                       'min_df' : params.get('min_df'),\n",
        "                       'max features' : params.get('max_features'),\n",
        "                       'Vectorizer' : str(type(self.classifier_set[0].\n",
        "                                               Vectorizer)).split('.')[-1].\n",
        "                                               split('\\'')[0],\n",
        "                       'precision' : precision_score(y_test,\n",
        "                                                     pred,\n",
        "                                                     average='macro'),\n",
        "                       'recall' : recall_score(y_test,\n",
        "                                               pred,\n",
        "                                               average='macro'),\n",
        "                       'f1-score' : f1_score(y_test,\n",
        "                                             pred,\n",
        "                                             average='macro'),\n",
        "                       'accuracy' : accuracy_score(y_test,\n",
        "                                                   pred)}\n",
        "    return report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eXQi8_5DC4d6",
        "outputId": "1b83a082-012d-4fa6-8b19-750a36f8d9b7"
      },
      "source": [
        "example = spamClassifierGrid()\n",
        "example.fit(x_train, y_train)\n",
        "result = example.getReport(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\program files\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8pRoT6ONC4d9",
        "outputId": "9a287774-4994-49ba-d4ea-e5134c0a91cc"
      },
      "source": [
        "result.sample(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Low word case Stop words n-gramm type n-gramm range  max_df  min_df  \\\n",
              "32           True       True         char        (1, 3)    1.00    0.25   \n",
              "3            True       True         char        (1, 3)    0.25    0.00   \n",
              "112          True       True         char       (5, 10)    0.75    0.00   \n",
              "30           True       True         char        (1, 3)    1.00    0.25   \n",
              "48           True       True         char        (1, 3)    1.00    0.75   \n",
              "11           True       True         char        (1, 3)    0.75    0.00   \n",
              "25           True       True         char        (1, 3)    0.75    0.25   \n",
              "57           True       True         char       (1, 10)    0.50    0.00   \n",
              "96           True       True         char       (1, 10)    1.00    0.75   \n",
              "23           True       True         char        (1, 3)    0.50    0.25   \n",
              "62           True       True         char       (1, 10)    0.75    0.00   \n",
              "103          True       True         char       (5, 10)    0.25    0.00   \n",
              "77           True       True         char       (1, 10)    0.75    0.25   \n",
              "84           True       True         char       (1, 10)    1.00    0.25   \n",
              "104          True       True         char       (5, 10)    0.25    0.00   \n",
              "89           True       True         char       (1, 10)    0.75    0.50   \n",
              "52           True       True         char       (1, 10)    0.25    0.00   \n",
              "118          True       True         char       (5, 10)    1.00    0.00   \n",
              "108          True       True         char       (5, 10)    0.50    0.00   \n",
              "22           True       True         char        (1, 3)    0.50    0.25   \n",
              "\n",
              "    max features       Vectorizer  precision    recall  f1-score  accuracy  \n",
              "32         10500  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "3          15250  TfidfVectorizer   0.975407  0.889877  0.926802  0.969516  \n",
              "112        10500  TfidfVectorizer   0.948705  0.925968  0.936914  0.971907  \n",
              "30          1000  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "48         15250  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "11          5750  TfidfVectorizer   0.975440  0.921007  0.945911  0.976689  \n",
              "25          1000  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "57         10500  TfidfVectorizer   0.966632  0.948487  0.957304  0.980873  \n",
              "96          5750  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "23         15250  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "62         10500  TfidfVectorizer   0.971198  0.949176  0.959813  0.982068  \n",
              "103        15250  TfidfVectorizer   0.960100  0.927689  0.943055  0.974895  \n",
              "77         10500  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "84         20000  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "104        20000  TfidfVectorizer   0.964817  0.928377  0.945546  0.976091  \n",
              "89         20000  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  \n",
              "52         10500  TfidfVectorizer   0.967554  0.953033  0.960130  0.982068  \n",
              "118        15250  TfidfVectorizer   0.960100  0.927689  0.943055  0.974895  \n",
              "108        15250  TfidfVectorizer   0.960100  0.927689  0.943055  0.974895  \n",
              "22         10500  TfidfVectorizer   0.434250  0.500000  0.464811  0.868500  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Low word case</th>\n",
              "      <th>Stop words</th>\n",
              "      <th>n-gramm type</th>\n",
              "      <th>n-gramm range</th>\n",
              "      <th>max_df</th>\n",
              "      <th>min_df</th>\n",
              "      <th>max features</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15250</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.975407</td>\n",
              "      <td>0.889877</td>\n",
              "      <td>0.926802</td>\n",
              "      <td>0.969516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.948705</td>\n",
              "      <td>0.925968</td>\n",
              "      <td>0.936914</td>\n",
              "      <td>0.971907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1000</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>15250</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5750</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.975440</td>\n",
              "      <td>0.921007</td>\n",
              "      <td>0.945911</td>\n",
              "      <td>0.976689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1000</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.966632</td>\n",
              "      <td>0.948487</td>\n",
              "      <td>0.957304</td>\n",
              "      <td>0.980873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>5750</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>15250</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.971198</td>\n",
              "      <td>0.949176</td>\n",
              "      <td>0.959813</td>\n",
              "      <td>0.982068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15250</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.960100</td>\n",
              "      <td>0.927689</td>\n",
              "      <td>0.943055</td>\n",
              "      <td>0.974895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>20000</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>20000</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.964817</td>\n",
              "      <td>0.928377</td>\n",
              "      <td>0.945546</td>\n",
              "      <td>0.976091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.50</td>\n",
              "      <td>20000</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 10)</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.967554</td>\n",
              "      <td>0.953033</td>\n",
              "      <td>0.960130</td>\n",
              "      <td>0.982068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15250</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.960100</td>\n",
              "      <td>0.927689</td>\n",
              "      <td>0.943055</td>\n",
              "      <td>0.974895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(5, 10)</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15250</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.960100</td>\n",
              "      <td>0.927689</td>\n",
              "      <td>0.943055</td>\n",
              "      <td>0.974895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>char</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>10500</td>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>0.434250</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.464811</td>\n",
              "      <td>0.868500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "YU9LjtCGC4d_",
        "outputId": "b9234c06-a4ab-44d0-f96d-360ffa14d2d5"
      },
      "source": [
        "result.iloc[result['precision'].argmax()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Low word case               True\n",
              "Stop words                  True\n",
              "n-gramm type                char\n",
              "n-gramm range            (1, 10)\n",
              "max_df                      0.25\n",
              "min_df                         0\n",
              "max features               20000\n",
              "Vectorizer       TfidfVectorizer\n",
              "precision               0.986096\n",
              "recall                  0.940221\n",
              "f1-score                0.961568\n",
              "accuracy                0.983264\n",
              "Name: 54, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "UswIFjZxC4eC",
        "outputId": "288caca5-7388-476d-92b0-814476359e9f"
      },
      "source": [
        "result.iloc[result['recall'].argmax()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Low word case               True\n",
              "Stop words                  True\n",
              "n-gramm type                char\n",
              "n-gramm range            (1, 10)\n",
              "max_df                      0.25\n",
              "min_df                         0\n",
              "max features               10500\n",
              "Vectorizer       TfidfVectorizer\n",
              "precision               0.967554\n",
              "recall                  0.953033\n",
              "f1-score                 0.96013\n",
              "accuracy                0.982068\n",
              "Name: 52, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6bttRWYZC4eF",
        "outputId": "28465d83-81d1-447b-ec32-0b2b34ea8cd3"
      },
      "source": [
        "result.iloc[result['f1-score'].argmax()]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Low word case               True\n",
              "Stop words                  True\n",
              "n-gramm type                char\n",
              "n-gramm range             (1, 3)\n",
              "max_df                      0.25\n",
              "min_df                         0\n",
              "max features                1000\n",
              "Vectorizer       TfidfVectorizer\n",
              "precision               0.982621\n",
              "recall                  0.948624\n",
              "f1-score                0.964748\n",
              "accuracy                0.984459\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QGGOue98C4eI",
        "outputId": "cee565bc-4f22-4ba9-8ca9-82b2590c25e1"
      },
      "source": [
        "result.iloc[result['accuracy'].argmax()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Low word case               True\n",
              "Stop words                  True\n",
              "n-gramm type                char\n",
              "n-gramm range             (1, 3)\n",
              "max_df                      0.25\n",
              "min_df                         0\n",
              "max features                1000\n",
              "Vectorizer       TfidfVectorizer\n",
              "precision               0.982621\n",
              "recall                  0.948624\n",
              "f1-score                0.964748\n",
              "accuracy                0.984459\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}